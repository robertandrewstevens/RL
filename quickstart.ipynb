{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1ffd8b",
   "metadata": {},
   "source": [
    "https://stable-baselines3.readthedocs.io/en/master/guide/quickstart.html\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Most of the library tries to follow a sklearn-like syntax for the Reinforcement Learning algorithms.\n",
    "\n",
    "Here is a quick example of how to train and run A2C on a CartPole environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f24616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145ef26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8482e83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.8     |\n",
      "|    ep_rew_mean        | 40.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 874      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | 0.644    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.822    |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.5     |\n",
      "|    ep_rew_mean        | 35.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 872      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.501   |\n",
      "|    explained_variance | -0.19    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -8.12    |\n",
      "|    value_loss         | 177      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32.4     |\n",
      "|    ep_rew_mean        | 32.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 869      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.659   |\n",
      "|    explained_variance | -0.0444  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    value_loss         | 6.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 31.1     |\n",
      "|    ep_rew_mean        | 31.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 870      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.566   |\n",
      "|    explained_variance | -0.0148  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -5.71    |\n",
      "|    value_loss         | 278      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 31.1     |\n",
      "|    ep_rew_mean        | 31.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 869      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.594   |\n",
      "|    explained_variance | -0.0113  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.95     |\n",
      "|    value_loss         | 4.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32       |\n",
      "|    ep_rew_mean        | 32       |\n",
      "| time/                 |          |\n",
      "|    fps                | 869      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.475   |\n",
      "|    explained_variance | -0.0317  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    value_loss         | 5.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35       |\n",
      "|    ep_rew_mean        | 35       |\n",
      "| time/                 |          |\n",
      "|    fps                | 869      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.454   |\n",
      "|    explained_variance | -0.039   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    value_loss         | 4.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.9     |\n",
      "|    ep_rew_mean        | 38.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 864      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.605   |\n",
      "|    explained_variance | 0.00299  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.941    |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 41.1     |\n",
      "|    ep_rew_mean        | 41.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 864      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.631   |\n",
      "|    explained_variance | 0.00126  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.988    |\n",
      "|    value_loss         | 3.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 46.2     |\n",
      "|    ep_rew_mean        | 46.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 861      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.616   |\n",
      "|    explained_variance | -0.00183 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.664    |\n",
      "|    value_loss         | 2.97     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 51.4      |\n",
      "|    ep_rew_mean        | 51.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 859       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.634    |\n",
      "|    explained_variance | -0.000326 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 0.589     |\n",
      "|    value_loss         | 2.52      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53.6     |\n",
      "|    ep_rew_mean        | 53.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 855      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.596   |\n",
      "|    explained_variance | 7.19e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.469    |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58       |\n",
      "|    ep_rew_mean        | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 858      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.605   |\n",
      "|    explained_variance | 0.000921 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.49     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 61.4      |\n",
      "|    ep_rew_mean        | 61.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 854       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.593    |\n",
      "|    explained_variance | -2.32e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.347     |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 67.7      |\n",
      "|    ep_rew_mean        | 67.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 850       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.631    |\n",
      "|    explained_variance | -4.27e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -23.3     |\n",
      "|    value_loss         | 3.52e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.4     |\n",
      "|    ep_rew_mean        | 71.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 851      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.557   |\n",
      "|    explained_variance | 0.000199 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.25     |\n",
      "|    value_loss         | 0.775    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 75.1     |\n",
      "|    ep_rew_mean        | 75.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 850      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.579   |\n",
      "|    explained_variance | 2.78e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.348    |\n",
      "|    value_loss         | 0.539    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 80.5      |\n",
      "|    ep_rew_mean        | 80.5      |\n",
      "| time/                 |           |\n",
      "|    fps                | 851       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.574    |\n",
      "|    explained_variance | -2.66e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 0.165     |\n",
      "|    value_loss         | 0.351     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84       |\n",
      "|    ep_rew_mean        | 84       |\n",
      "| time/                 |          |\n",
      "|    fps                | 854      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.15     |\n",
      "|    value_loss         | 0.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 86.6     |\n",
      "|    ep_rew_mean        | 86.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 855      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.374   |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.231    |\n",
      "|    value_loss         | 0.0908   |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b43b1",
   "metadata": {},
   "source": [
    "Or just train a model with a one liner if the environment is registered in Gym and if the policy is registered:\n",
    "\n",
    "https://github.com/openai/gym/wiki/Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc070a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C('MlpPolicy', 'CartPole-v1').learn(10000)\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e40e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
